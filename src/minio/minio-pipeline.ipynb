{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "initial_id",
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "import kfp\n",
    "from kfp import dsl, kubernetes\n",
    "from kfp.dsl import Dataset, Input, Output, Model\n",
    "from typing import NamedTuple\n",
    "\n",
    "# Step 1: 加载、构建、训练模型.\n",
    "@dsl.component(\n",
    "    base_image=\"ghcr.io/kubeflow/kubeflow/notebook-servers/jupyter-tensorflow-full:v1.10.0\",\n",
    "    packages_to_install=[\"pandas\", \"minio\", \"numpy\"]\n",
    ")\n",
    "def train_model():\n",
    "    import numpy as np\n",
    "    import pandas as pd\n",
    "    import matplotlib.pyplot as plt\n",
    "    from tensorflow import keras\n",
    "    import tensorflow as tf\n",
    "    import os\n",
    "    import minio\n",
    "    import glob\n",
    "    from minio import Minio\n",
    "\n",
    "    (x_train, y_train), (x_test, y_test) = keras.datasets.mnist.load_data()\n",
    "    # check shape of the data\n",
    "\n",
    "    print(f\"x_train shape: {x_train.shape}\")\n",
    "    print(f\"y_train shape: {y_train.shape}\")\n",
    "\n",
    "    print(f\"x_test shape: {x_test.shape}\")\n",
    "    print(f\"y_test shape: {y_test.shape}\")\n",
    "    # visualize single data instances\n",
    "\n",
    "    img_no = 0 #change the number to display other examples\n",
    "\n",
    "    first_number = x_train[img_no]\n",
    "    plt.imshow(first_number, cmap='gray') # visualize the numbers in gray mode\n",
    "    plt.show()\n",
    "    print(f\"correct number: {y_train[img_no]}\")\n",
    "    # reshaping the data\n",
    "    # reshaping pixels in a 28x28px image with greyscale, canal = 1. This is needed for the Keras API\n",
    "    x_train = x_train.reshape(-1,28,28,1)\n",
    "    x_test = x_test.reshape(-1,28,28,1)\n",
    "\n",
    "    # normalizing the data\n",
    "    # each pixel has a value between 0-255. Here we divide by 255, to get values from 0-1\n",
    "    x_train = x_train / 255\n",
    "    x_test = x_test / 255\n",
    "\n",
    "    print(f\"train X shape: {x_train.shape}\")\n",
    "    print(f\"test X shape: {x_test.shape}\")\n",
    "    model = keras.models.Sequential()\n",
    "    model.add(keras.layers.Conv2D(64, (3, 3), activation='relu', input_shape=(28,28,1)))\n",
    "    model.add(keras.layers.MaxPool2D(2, 2))\n",
    "\n",
    "    model.add(keras.layers.Conv2D(64, (3, 3), activation='relu'))\n",
    "    model.add(keras.layers.MaxPool2D(2, 2))\n",
    "\n",
    "    model.add(keras.layers.Conv2D(64, (3, 3), activation='relu'))\n",
    "    model.add(keras.layers.MaxPool2D(2, 2))\n",
    "\n",
    "    model.add(keras.layers.Flatten())\n",
    "    model.add(keras.layers.Dense(64, activation='relu'))\n",
    "\n",
    "    model.add(keras.layers.Dense(32, activation='relu'))\n",
    "\n",
    "    model.add(keras.layers.Dense(10, activation='softmax')) #output are 10 classes, numbers from 0-9\n",
    "\n",
    "    #show model summary - how it looks\n",
    "    model.summary()\n",
    "    #compile the model - we want to have a multiple outcome\n",
    "    model.compile(optimizer=\"adam\",\n",
    "                  loss=\"sparse_categorical_crossentropy\",\n",
    "                  metrics=['accuracy'])\n",
    "    #fit the model and return the history while training\n",
    "    history = model.fit(\n",
    "        x=x_train,\n",
    "        y=y_train,\n",
    "        epochs=1\n",
    "    )\n",
    "    print(\"======训练结束=========\")\n",
    "    # 检查并创建目录 (exist_ok=True 表示如果文件夹已存在则不报错)\n",
    "    save_path = \"/tmp/models/detect-digits.keras\"\n",
    "    os.makedirs(os.path.dirname(save_path), exist_ok=True)\n",
    "    keras.models.save_model(model, save_path)\n",
    "\n",
    "\n",
    "    # 1. 初始化 MinIO 客户端 (保持你的配置)\n",
    "    minio_client = Minio(\n",
    "        \"minio-service.kubeflow:9000\",\n",
    "        access_key=\"minio\",\n",
    "        secret_key=\"minio123\",\n",
    "        secure=False\n",
    "    )\n",
    "    minio_bucket = \"mlpipeline\"\n",
    "\n",
    "    def smart_upload_to_minio(local_path, bucket_name, minio_base_path):\n",
    "        \"\"\"\n",
    "        智能上传函数：自动识别文件或文件夹并上传到 MinIO\n",
    "        \"\"\"\n",
    "        if not os.path.exists(local_path):\n",
    "            print(f\"错误: 本地路径 {local_path} 不存在\")\n",
    "            return\n",
    "\n",
    "        if os.path.isfile(local_path):\n",
    "            # 如果是单个文件 (针对 Keras 3 的 .keras 文件)\n",
    "            file_name = os.path.basename(local_path)\n",
    "            remote_path = os.path.join(minio_base_path, file_name).replace(os.sep, '/')\n",
    "            minio_client.fput_object(bucket_name, remote_path, local_path)\n",
    "            print(f\"成功上传文件: {local_path} -> {remote_path}\")\n",
    "\n",
    "        elif os.path.isdir(local_path):\n",
    "            # 如果是文件夹 (针对旧版 SavedModel 格式)\n",
    "            for root, dirs, files in os.walk(local_path):\n",
    "                for file in files:\n",
    "                    local_file = os.path.join(root, file)\n",
    "                    # 计算相对路径，保持文件夹结构\n",
    "                    rel_path = os.path.relpath(local_file, local_path)\n",
    "                    remote_path = os.path.join(minio_base_path, rel_path).replace(os.sep, '/')\n",
    "\n",
    "                    minio_client.fput_object(bucket_name, remote_path, local_file)\n",
    "                    print(f\"成功上传文件夹内文件: {local_file} -> {remote_path}\")\n",
    "\n",
    "\n",
    "    smart_upload_to_minio(\n",
    "        local_path=save_path,\n",
    "        bucket_name=minio_bucket,\n",
    "        minio_base_path=\"models\"  # 在 MinIO 里存放在 models 目录下\n",
    "    )\n",
    "    # 最终路径 - s3://mlpipeline/models/detect-digits.keras\n",
    "    print(\"s3://mlpipeline/models/detect-digits.keras\")\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "\n",
    "@dsl.component(\n",
    "    base_image=\"ghcr.io/kubeflow/kubeflow/notebook-servers/jupyter-tensorflow-full:v1.10.0\",\n",
    "    packages_to_install=[\"minio\", \"kserve==0.11.0\", \"kubernetes\"]\n",
    ")\n",
    "def deploy_model_to_kserve():\n",
    "    def deploy_model_to_kserve_func(\n",
    "            model: object,\n",
    "            service_name: str,\n",
    "            namespace: str\n",
    "    ):\n",
    "        from kserve import KServeClient\n",
    "        from kserve import V1beta1InferenceService\n",
    "        from kserve import V1beta1InferenceServiceSpec\n",
    "        from kserve import V1beta1PredictorSpec\n",
    "        from kserve import V1beta1SKLearnSpec\n",
    "        from kubernetes import client as k8s_client\n",
    "\n",
    "        # 手动配置 Token 和 Host\n",
    "        configuration = k8s_client.Configuration()\n",
    "        configuration.host = \"http://kserve-controller-manager-service.kubeflow:8443\" # 或者是 API Server 地址\n",
    "        configuration.verify_ssl = False # 生产环境建议开启并配置证书\n",
    "        configuration.api_key = {\"authorization\": \"Bearer \" + \"ACCESS_TOKEN\"}\n",
    "        # 创建 KServe 客户端\n",
    "        kserve_client = KServeClient(client_configuration=configuration)\n",
    "\n",
    "        # 定义 InferenceService 结构\n",
    "        # 注意：对于 Scikit-Learn 模型，KServe 需要存储路径包含 joblib/pickle 文件\n",
    "        isvc = V1beta1InferenceService(\n",
    "            api_version=\"serving.kserve.io/v1beta1\",\n",
    "            kind=\"InferenceService\",\n",
    "            metadata=k8s_client.V1ObjectMeta(\n",
    "                name=service_name,\n",
    "                namespace=namespace,\n",
    "                annotations={'sidecar.istio.io/inject': 'false'}\n",
    "            ),\n",
    "            spec=V1beta1InferenceServiceSpec(\n",
    "                predictor=V1beta1PredictorSpec(\n",
    "                    sklearn=V1beta1SKLearnSpec(\n",
    "                        # model.uri 会自动转换为 s3:// 或 gs:// 路径\n",
    "                        storage_uri=model.uri\n",
    "                    )\n",
    "                )\n",
    "            )\n",
    "        )\n",
    "\n",
    "        # 执行部署 (如果已存在则 patch，不存在则 create)\n",
    "        try:\n",
    "            kserve_client.create(isvc)\n",
    "            print(f\"Service {service_name} created.\")\n",
    "        except:\n",
    "            kserve_client.patch(service_name, isvc)\n",
    "            print(f\"Service {service_name} updated.\")\n",
    "\n",
    "    from types import SimpleNamespace\n",
    "    server=deploy_model_to_kserve_func(\n",
    "        model=SimpleNamespace(uri=\"s3://mlpipeline/models/detect-digits.keras\"),\n",
    "        # model=SimpleNamespace(uri=\"models/detect-digits.keras\"),\n",
    "        service_name=\"detect-digits-2\",\n",
    "        namespace=\"kubeflow-user-example-com\"\n",
    "    )\n",
    "    print(f\"Service detect-digits created.{server}\")\n",
    "    "
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "78430ae12f47dff"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "import kfp\n",
    "from kfp import dsl\n",
    "\n",
    "@dsl.pipeline(\n",
    "    name=\"detect_digits_pipeline\",\n",
    "    description=\"detect digits pipeline demo\"\n",
    ")\n",
    "def detect_digits_pipeline():\n",
    "    # 1. 运行训练任务\n",
    "    train_task = train_model()\n",
    "    train_task.set_cpu_limit('1').set_memory_limit('4G')\n",
    "    # GPU资源\n",
    "    train_task.set_accelerator_limit(1)\n",
    "    train_task.add_node_selector_constraint('nvidia.com/gpu')\n",
    "    kubernetes.add_node_selector(\n",
    "        train_task,\n",
    "        label_key='nvidia.com/gpu.product',\n",
    "        label_value='NVIDIA-GeForce-RTX-3090',\n",
    "    )\n",
    "\n",
    "    deploy_task = deploy_model_to_kserve()\n",
    "    deploy_task.after(train_task) \n",
    "    "
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "8ac163b22683e6de"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# Step 5: Compile\n",
    "from kfp import compiler\n",
    "\n",
    "compiler.Compiler().compile(detect_digits_pipeline, 'detect_digits_pipeline.yaml')\n",
    "\n",
    "# Step 6: Run\n",
    "from kfp.client import Client\n",
    "\n",
    "client = Client(host='http://ml-pipeline.kubeflow:8888',\n",
    "                namespace=\"kubeflow-user-example-com\",\n",
    "                existing_token=\"ACCESS_TOKEN\",\n",
    "                verify_ssl=False)\n",
    "run = client.create_run_from_pipeline_package(\n",
    "    'detect_digits_pipeline.yaml',\n",
    "    enable_caching=False,  # 依然有效\n",
    "    experiment_name='detect_digits_pipeline-test-experiment'\n",
    ")\n"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "4b5ecf00dcc93c2b"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
